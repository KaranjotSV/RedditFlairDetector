{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "from praw.models import MoreComments\n",
    "import regex\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import os\n",
    "\n",
    "reddit = praw.Reddit(client_id = 'gb2ZbwyyADJBbw', client_secret = 'nGdE_EtfK8pM20dGy369ZmOJxOg', \n",
    "                     user_agent = 'SubScraper', username = 'KaranjotSinghV', password = 'jogindersinghvilkhu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_entries = {}\n",
    "chosen_subject = 'india'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here!! Extracting using .search(f\"flair:{flair}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1 = reddit.subreddit(chosen_subject)\n",
    "postids_sub1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flairs = [\"AskIndia\", \"Non-Political\", \"Coronavirus\", \"Photography\", \"Science/Technology\", \"Business/Finance\", \n",
    "          \"Policy/Economy\", \"Sports\", \"Food\", \"Politics\", \"Scheduled\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Func for collecting Post Data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectSubData1(submission, flair):\n",
    "    \n",
    "    post = reddit.submission(id = submission) #Accessing subreddit post using id\n",
    "    \n",
    "    unique = post.id\n",
    "    title = post.title\n",
    "    url = post.url\n",
    "    body = post.selftext\n",
    "    score = post.score  \n",
    "    commentsCount = post.num_comments\n",
    "    timeStamp = post.created_utc\n",
    "    \n",
    "    flairRetrieved = post.link_flair_text\n",
    "    \n",
    "    post.comments.replace_more(limit=None)\n",
    "    \n",
    "    comments = ''    \n",
    "    count = 0\n",
    "    \n",
    "    for top_level_comment in post.comments:\n",
    "        \n",
    "        comments = comments + ' ' + top_level_comment.body\n",
    "        count += 1     \n",
    "        \n",
    "        if(count > 10):\n",
    "            break\n",
    "    \n",
    "    subData = list() #list to store key data of a post\n",
    "    \n",
    "    if flairRetrieved == flair: #sanity check\n",
    "        \n",
    "        subData.append((unique, title, url, body, score, comments, commentsCount, timeStamp, flairRetrieved))\n",
    "        post_entries[unique] = subData\n",
    "        postids_sub1.append(post.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for flair in flairs:\n",
    "    \n",
    "    print(\"Retrieving Posts for \" + str(flair))\n",
    "    get_subreddits = sub1.search(f\"flair:{flair}\", limit = 300)\n",
    "\n",
    "    for submission in get_subreddits:\n",
    "\n",
    "        collectSubData1(submission.id, flair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Number of posts retrieved - \" + str(len(postids_sub1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "post_entries[postids_sub1[100]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating .csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createcsv():\n",
    "    upload_count = 0\n",
    "    \n",
    "    import csv\n",
    "    \n",
    "    location = '/home/vilkhu/MIDAS 2020/Data/'\n",
    "    filename = input()\n",
    "    file = location + filename\n",
    "    \n",
    "    with open(file, 'w', newline = '') as file:\n",
    "        \n",
    "        a = csv.writer(file, delimiter = ',')\n",
    "        \n",
    "        headers = [\"Post ID\", \"Title\", \"URL\", \"Body\", \"Score\", \"Comments\", \"Comments Count\", \"Time Stamp\", \"Flair\"]\n",
    "        \n",
    "        a.writerow(headers)\n",
    "        \n",
    "        for post in post_entries:\n",
    "            a.writerow(post_entries[post][0])\n",
    "            upload_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createcsv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>URL</th>\n",
       "      <th>Body</th>\n",
       "      <th>Score</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Comments Count</th>\n",
       "      <th>Time Stamp</th>\n",
       "      <th>Flair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g014wc</td>\n",
       "      <td>Lost my Job, Sick Mother and Paralysed Dad, In...</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g014wc...</td>\n",
       "      <td>Hi....It's really tough time for everyone. I r...</td>\n",
       "      <td>1048</td>\n",
       "      <td>I'm a freelancer. Don't listen to the idiots ...</td>\n",
       "      <td>131</td>\n",
       "      <td>1.586713e+09</td>\n",
       "      <td>AskIndia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fxofyu</td>\n",
       "      <td>Why does the government come with a begging bo...</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/fxofyu...</td>\n",
       "      <td>We have floods, terrorist attacks, famines due...</td>\n",
       "      <td>646</td>\n",
       "      <td>I don't understand why they don't use money f...</td>\n",
       "      <td>204</td>\n",
       "      <td>1.586419e+09</td>\n",
       "      <td>AskIndia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g0zlly</td>\n",
       "      <td>Mother's condition is going worse due to hepat...</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g0zlly...</td>\n",
       "      <td>Hi folks, I really appreciate the warm respons...</td>\n",
       "      <td>763</td>\n",
       "      <td>If anyone knows who is influential on Twitter...</td>\n",
       "      <td>94</td>\n",
       "      <td>1.586842e+09</td>\n",
       "      <td>AskIndia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fvy95j</td>\n",
       "      <td>Men who are 30+ and have decided not to get ma...</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/fvy95j...</td>\n",
       "      <td>The corona virus has given me some time to thi...</td>\n",
       "      <td>266</td>\n",
       "      <td>Plan your finances. Work and enjoy in your ow...</td>\n",
       "      <td>206</td>\n",
       "      <td>1.586178e+09</td>\n",
       "      <td>AskIndia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g1lmhg</td>\n",
       "      <td>[Please Advice] Reality punched me in the face...</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g1lmhg...</td>\n",
       "      <td>Sorry Reddit, this post is going to be long. P...</td>\n",
       "      <td>430</td>\n",
       "      <td>One thing I will say is don't try to clear of...</td>\n",
       "      <td>83</td>\n",
       "      <td>1.586928e+09</td>\n",
       "      <td>AskIndia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Post ID                                              Title  \\\n",
       "0  g014wc  Lost my Job, Sick Mother and Paralysed Dad, In...   \n",
       "1  fxofyu  Why does the government come with a begging bo...   \n",
       "2  g0zlly  Mother's condition is going worse due to hepat...   \n",
       "3  fvy95j  Men who are 30+ and have decided not to get ma...   \n",
       "4  g1lmhg  [Please Advice] Reality punched me in the face...   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://www.reddit.com/r/india/comments/g014wc...   \n",
       "1  https://www.reddit.com/r/india/comments/fxofyu...   \n",
       "2  https://www.reddit.com/r/india/comments/g0zlly...   \n",
       "3  https://www.reddit.com/r/india/comments/fvy95j...   \n",
       "4  https://www.reddit.com/r/india/comments/g1lmhg...   \n",
       "\n",
       "                                                Body  Score  \\\n",
       "0  Hi....It's really tough time for everyone. I r...   1048   \n",
       "1  We have floods, terrorist attacks, famines due...    646   \n",
       "2  Hi folks, I really appreciate the warm respons...    763   \n",
       "3  The corona virus has given me some time to thi...    266   \n",
       "4  Sorry Reddit, this post is going to be long. P...    430   \n",
       "\n",
       "                                            Comments  Comments Count  \\\n",
       "0   I'm a freelancer. Don't listen to the idiots ...             131   \n",
       "1   I don't understand why they don't use money f...             204   \n",
       "2   If anyone knows who is influential on Twitter...              94   \n",
       "3   Plan your finances. Work and enjoy in your ow...             206   \n",
       "4   One thing I will say is don't try to clear of...              83   \n",
       "\n",
       "     Time Stamp     Flair  \n",
       "0  1.586713e+09  AskIndia  \n",
       "1  1.586419e+09  AskIndia  \n",
       "2  1.586842e+09  AskIndia  \n",
       "3  1.586178e+09  AskIndia  \n",
       "4  1.586928e+09  AskIndia  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv('Data/PRAW-Data.csv')\n",
    "data_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of posts retrieved - 2656\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of posts retrieved - \" + str(data_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Politics              249\n",
       "Coronavirus           249\n",
       "Scheduled             246\n",
       "Science/Technology    245\n",
       "Policy/Economy        245\n",
       "Non-Political         244\n",
       "Business/Finance      243\n",
       "Food                  242\n",
       "Photography           241\n",
       "AskIndia              235\n",
       "Sports                217\n",
       "Name: Flair, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[\"Flair\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here!! Extracting hot, new, rising, top posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is another method of extracting posts, the posts are categorized as hot, new, rising and top. This method was not opted because the number of posts retrieved for each Flair is not balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postids_sub2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub2 = reddit.subreddit(chosen_subject).hot(limit = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for submission in sub2:\n",
    "    \n",
    "    postids_sub2.append(submission.id)\n",
    "    \n",
    "postids_sub2 = list(np.unique(postids_sub2))\n",
    "postids_sub2 = [elem for elem in postids_sub2 if elem not in postids_sub1]\n",
    "print(\"Number of IDs retrieved - \" + str(len(postids_sub2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Func for collecting Post Data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectSubData2(submission):\n",
    "    \n",
    "    post = reddit.submission(id = submission) #Accessing subreddit post using id\n",
    "    \n",
    "    post.comments.replace_more(limit=None)\n",
    "    \n",
    "    comments = ''    \n",
    "    count = 0\n",
    "    \n",
    "    for top_level_comment in post.comments:\n",
    "        \n",
    "        comments = comments + ' ' + top_level_comment.body\n",
    "        count += 1     \n",
    "        \n",
    "        if(count > 10):\n",
    "            break\n",
    "    \n",
    "    unique = post.id\n",
    "    \n",
    "    title = post.title\n",
    "    \n",
    "    url = post.url\n",
    "    \n",
    "    body = post.selftext\n",
    "    \n",
    "    timeStamp = post.created_utc\n",
    "    \n",
    "    commentsCount = post.num_comments\n",
    "    \n",
    "    score = post.score\n",
    "         \n",
    "    flair = post.link_flair_text\n",
    "    \n",
    "    subData = list() #list to store key data of a post\n",
    "    \n",
    "    if flair in flairs:\n",
    "    \n",
    "        subData.append((unique, title, url, body, score, comments, commentsCount, timeStamp, flair))\n",
    "        post_entries[unique] = subData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count, submission in enumerate(postids_sub2):\n",
    "    \n",
    "    print('Collecting data for post - ' + str(count))\n",
    "    \n",
    "    collectSubData2(submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
